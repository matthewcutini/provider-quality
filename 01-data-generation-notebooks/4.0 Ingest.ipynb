{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e2c59cb-e6e8-4ffd-84b0-604883998801",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Ingest files into Delta tables"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the base path to the landing folder\n",
    "base_path = \"/Volumes/mcutini/synthea/landing/\"\n",
    "\n",
    "# Get all subdirectories in the base path\n",
    "subdirectories = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "\n",
    "# Remove the 'notes' folder from the subdirectories list\n",
    "subdirectories = [d for d in subdirectories if d != 'notes']\n",
    "\n",
    "print(subdirectories)\n",
    "\n",
    "# Iterate over each subdirectory and process the files\n",
    "for subdir in subdirectories:\n",
    "    file_path = os.path.join(base_path, subdir)\n",
    "    \n",
    "    # Read the files into a DataFrame\n",
    "    df = spark.read.format(\"csv\").option(\"header\", \"true\").load(file_path)\n",
    "    \n",
    "    # Write the DataFrame to a Delta table\n",
    "    table_name = f\"mcutini.synthea.{subdir}\"\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da09400e-2e61-4bb6-b78c-226ed55107ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the notes folder\n",
    "notes_path = \"/Volumes/mcutini/synthea/synthetic_files_raw/output/notes/\"\n",
    "\n",
    "# Get all files in the notes folder\n",
    "note_files = [f for f in os.listdir(notes_path) if os.path.isfile(os.path.join(notes_path, f))]\n",
    "\n",
    "# Create a list to hold the file data\n",
    "data = []\n",
    "\n",
    "# Iterate over each file and read its content\n",
    "for note_file in note_files:\n",
    "    file_path = os.path.join(notes_path, note_file)\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_text = file.read()\n",
    "        data.append((note_file, file_text))\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "notes_df = spark.createDataFrame(data, [\"file_name\", \"file_text\"])\n",
    "\n",
    "# Write the DataFrame to a Delta table\n",
    "notes_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"mcutini.synthea.notes\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "4.0 Ingest",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
